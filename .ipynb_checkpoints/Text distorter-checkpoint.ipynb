{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data generation\n",
    "\n",
    "In this notebook, we will generate the training data for the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Global setup\n",
    "Set up logging and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"global_setup.py\") as setupfile:\n",
    "        exec(setupfile.read())\n",
    "except FileNotFoundError:\n",
    "    print('Setup already completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import pprint\n",
    "from src.wikipedia import Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text distortion function\n",
    "\n",
    "<i>distortText</i> function takes two parameters: <br><br>\n",
    "text: string\n",
    "swap_type: string; values:\n",
    "* <i>symbolswap</i>: for each word in a sentence, take two consequent symbols and swap them (orange - oragne)\n",
    "* <i>symboldelete</i>: for each word in a sentence, delete a random symbol (orange - ornge)\n",
    "* <i>symbolreplacerandom</i>: for each word in a sentence, replace a symbol with a random symbol from the alphabet (orange - xrange)\n",
    "* <i>symbolreplaceprev</i>: for each word in a sentence, replace a symbol with a previous symbol (orange - orrnge)\n",
    "* <i>wordtrimright</i>: for each word in a sentence, remove a random number of symbols from the right (orange - o)\n",
    "* <i>wordswapprev</i>: take two consequent words in one sentence and swap them (I like oranges - like I oranges)\n",
    "* <i>deletespaces</i>: delete whitespace between two consequent words in a sentence (I like oranges - Ilike oranges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortText(text, swap_type = \"symboldelete\"):\n",
    "       \n",
    "    # Distortion types\n",
    "    distortions_symbols = [\"symbolswap\",\"symboldelete\",\"symbolreplacerandom\",\"symbolreplaceprev\"]\n",
    "    distortions_words = [\"wordtrimright\", \"wordswapprev\"]\n",
    "    distortions_sentences = [\"deletespaces\"]\n",
    "    # Symbol operations: max 2 symbols per word, max 2 symbol distortion types per word\n",
    "    # Word trim: max 1 per word\n",
    "    # Delete spaces: max all spaces, min 0 spaces\n",
    "    \n",
    "    list_words = text.split()\n",
    "    \n",
    "    distortion_prob_symbol = 0.5\n",
    "    for i in range(len(list_words)):\n",
    "        r = random.random()\n",
    "        if swap_type == \"symbolswap\":\n",
    "            # SYMBOL SWAP\n",
    "            ## min distorted symbol = 0, max distorted symbol = len-2 because of indexing with 0 and this is the 1st swappable symbol\n",
    "            distorted_symbol = round((len(list_words[i]) - 2) * random.random())\n",
    "            s1 = list_words[i][distorted_symbol + 1]\n",
    "            #print(\"{}---{}-{}-{}-{}\".format(distorted_symbol, list_words[i][0:distorted_symbol - 1], list_words[i][distorted_symbol], s1, list_words[i][distorted_symbol + 1:]))\n",
    "            #print(list_words[i][0:(distorted_symbol - 1) * (distorted_symbol > 0)])\n",
    "            list_words[i] = list_words[i][0:distorted_symbol] + s1 + list_words[i][distorted_symbol] + list_words[i][distorted_symbol + 2:]\n",
    "        elif swap_type == \"symboldelete\":\n",
    "            # SYMBOL DELETE\n",
    "            ## min distorted symbol = 0, max distorted symbol = len-1\n",
    "            distorted_symbol = round((len(list_words[i]) - 1) * random.random())\n",
    "            list_words[i] = list_words[i][0:distorted_symbol] + list_words[i][distorted_symbol + 1:]\n",
    "        elif swap_type == \"symbolreplacerandom\":\n",
    "            symbols = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "            # SYMBOL REPLACE RANDOM\n",
    "            ## min distorted symbol = 0, max distorted symbol = len-1\n",
    "            distorted_symbol = round((len(list_words[i]) - 1) * random.random())\n",
    "            replace = symbols[round((len(symbols) - 1) * random.random())]\n",
    "            list_words[i] = list_words[i][0:distorted_symbol] + replace + list_words[i][distorted_symbol + 1:]\n",
    "        elif swap_type == \"symbolreplaceprev\":\n",
    "            # SYMBOL REPLACE PREVIOUS\n",
    "            ## min distorted symbol = 1, max distorted symbol = len - 1\n",
    "            distorted_symbol = round(1 + (len(list_words[i]) - 2) * random.random())\n",
    "            #print(\"{} - {}\".format(distorted_symbol, list_words[i]))\n",
    "            #print(\"{}---{}-{}-{}\".format(distorted_symbol, list_words[i][0:(distorted_symbol)], list_words[i][distorted_symbol - 1], list_words[i][distorted_symbol + 1 * (len(list_words[i]) > distorted_symbol):distorted_symbol + 1 * (len(list_words[i]) > distorted_symbol)]))\n",
    "            list_words[i] = list_words[i][0:(distorted_symbol)] + list_words[i][distorted_symbol - 1] + list_words[i][distorted_symbol + 1:]\n",
    "        \n",
    "        if swap_type == \"wordtrimright\":\n",
    "            # WORD TRIM RIGHT\n",
    "            ## min symbol = 1, max distorted symbol = len - 1\n",
    "            trim_from = round(1 + (len(list_words[i]) - 1) * random.random())\n",
    "            list_words[i] = list_words[i][:trim_from]\n",
    "    \n",
    "    if swap_type == \"wordswapprev\":\n",
    "        # WORD SWAP\n",
    "        word_id = round((len(list_words) - 2) * random.random())\n",
    "        s1 = list_words[word_id]\n",
    "        list_words[word_id] = list_words[word_id + 1]\n",
    "        list_words[word_id + 1] = s1\n",
    "        \n",
    "    if swap_type == \"deletespaces\":\n",
    "        # DELETE WHITESPACES\n",
    "        ## -2 because there are len - 1 spaces in total\n",
    "        space_id = round((len(list_words) - 2) * random.random())\n",
    "        list_words[space_id] = list_words[space_id] + list_words[space_id + 1]\n",
    "        list_words.pop(space_id + 1)\n",
    "            \n",
    "    distortedText = \" \".join(list_words)\n",
    "    return distortedText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the distortion function on a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Antons likes pizza\"\n",
    "print(distortText(text=text,swap_type=\"symbolswap\"))\n",
    "\n",
    "print(distortText(text=text,swap_type=\"symboldelete\"))\n",
    "\n",
    "print(distortText(text=text,swap_type=\"symbolreplacerandom\"))\n",
    "\n",
    "print(distortText(text=text,swap_type=\"symbolreplaceprev\"))\n",
    "\n",
    "print(distortText(text=text,swap_type=\"wordtrimright\"))\n",
    "\n",
    "print(distortText(text=text,swap_type=\"wordswapprev\"))\n",
    "\n",
    "print(distortText(text=text,swap_type=\"deletespaces\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the Simple Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = Wikipedia(\n",
    "    language=\"simple\",\n",
    "    cache_directory_url=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clean-up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up simple wikipedia texts\n",
    "pattern_ignored_words = re.compile(\n",
    "    r\"\"\"\n",
    "    (?:(?:thumb|thumbnail|left|right|\\d+px|upright(?:=[0-9\\.]+)?)\\|)+\n",
    "    |^\\s*\\|.+$\n",
    "    |^REDIRECT\\b\"\"\",\n",
    "    flags=re.DOTALL | re.UNICODE | re.VERBOSE | re.MULTILINE)\n",
    "pattern_new_lines = re.compile('[\\n\\r ]+', re.UNICODE)\n",
    "texts = [wikipedia.documents[i].text for i in range(len(wikipedia.documents))]\n",
    "texts = [pattern_ignored_words.sub('', texts[i]) for i in range(len(texts))]\n",
    "texts = [pattern_new_lines.sub(' ', texts[i]) for i in range(len(texts))]\n",
    "texts = [texts[i].replace(\"\\\\\", \"\") for i in range(len(texts))]\n",
    "texts = [texts[i].replace(\"\\xa0\", \" \") for i in range(len(texts))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Divide into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple wikipedia article texts into single sentences\n",
    "sentences = []\n",
    "sentences += [tokenize.sent_tokenize(texts[i]) for i in range(len(texts))]\n",
    "#sentences += [texts[i].split(\". \") for i in range(len(texts))] #len(texts)\n",
    "# Now sentences is a list of lists. The next expression flattens it into one long list.\n",
    "sentences = [item for sublist in sentences for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clean-up sentences and remove too long and short ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median sentence length is 83 symbols. We remove the sentences shorter than 20 symbols and longer than 100 symbols to clean up the dataset.<br><br>\n",
    "We also remove the sentences starting with \"Category:\", \"Related pages\", \"References\", \"Other websites:\". <br>\n",
    "These are technical Wikipedia pages that we do not need. Need to check for more, e.g. \"Gallery\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sentences))\n",
    "for i in reversed(range(len(sentences))):\n",
    "    if len(sentences[i]) < 20 or len(sentences[i]) > 100 \\\n",
    "        or sentences[i][0:9] == \"Category:\" \\\n",
    "        or sentences[i][0:13] == \"Related pages\" \\\n",
    "        or sentences[i][0:10] == \"References\" \\\n",
    "        or sentences[i][0:14] == \"Other websites\":\n",
    "        sentences.pop(i)\n",
    "print(len(sentences))\n",
    "\n",
    "#Gallery - do something?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sentences # first run on \n",
    "for sentence in sentences:\n",
    "    pass #apply distortion function here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
