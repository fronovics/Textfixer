{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"global_setup.py\") as setupfile:\n",
    "        exec(setupfile.read())\n",
    "except FileNotFoundError:\n",
    "    print('Setup already completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import pprint\n",
    "from src.wikipedia import Wikipedia\n",
    "#random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortText(text, swap_type = \"symboldelete\"):\n",
    "       \n",
    "    # Distortion types\n",
    "    distortions_symbols = [\"symbolswap\",\"symboldelete\",\"symbolreplacerandom\",\"symbolreplaceprev\"]\n",
    "    distortions_words = [\"wordtrimright\", \"wordswapprev\"]\n",
    "    distortions_sentences = [\"deletespaces\"]\n",
    "    # Symbol operations: max 2 symbols per word, max 2 symbol distortion types per word\n",
    "    # Word trim: max 1 per word\n",
    "    # Delete spaces: max all spaces, min 0 spaces\n",
    "    \n",
    "    list_words = text.split()\n",
    "    \n",
    "    distortion_prob_symbol = 0.5\n",
    "    for i in range(len(list_words)):\n",
    "        r = random.random()\n",
    "        if swap_type == \"symbolswap\":\n",
    "            # SYMBOL SWAP\n",
    "            ## min distorted symbol = 0, max distorted symbol = len-2 because of indexing with 0 and this is the 1st swappable symbol\n",
    "            distorted_symbol = round((len(list_words[i]) - 2) * random.random())\n",
    "            s1 = list_words[i][distorted_symbol + 1]\n",
    "            #print(\"{}---{}-{}-{}-{}\".format(distorted_symbol, list_words[i][0:distorted_symbol - 1], list_words[i][distorted_symbol], s1, list_words[i][distorted_symbol + 1:]))\n",
    "            #print(list_words[i][0:(distorted_symbol - 1) * (distorted_symbol > 0)])\n",
    "            list_words[i] = list_words[i][0:distorted_symbol] + s1 + list_words[i][distorted_symbol] + list_words[i][distorted_symbol + 2:]\n",
    "        elif swap_type == \"symboldelete\":\n",
    "            # SYMBOL DELETE\n",
    "            ## min distorted symbol = 0, max distorted symbol = len-1\n",
    "            distorted_symbol = round((len(list_words[i]) - 1) * random.random())\n",
    "            list_words[i] = list_words[i][0:distorted_symbol] + list_words[i][distorted_symbol + 1:]\n",
    "        elif swap_type == \"symbolreplacerandom\":\n",
    "            symbols = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "            # SYMBOL REPLACE RANDOM\n",
    "            ## min distorted symbol = 0, max distorted symbol = len-1\n",
    "            distorted_symbol = round((len(list_words[i]) - 1) * random.random())\n",
    "            replace = symbols[round((len(symbols) - 1) * random.random())]\n",
    "            list_words[i] = list_words[i][0:distorted_symbol] + replace + list_words[i][distorted_symbol + 1:]\n",
    "        elif swap_type == \"symbolreplaceprev\":\n",
    "            # SYMBOL REPLACE PREVIOUS\n",
    "            ## min distorted symbol = 1, max distorted symbol = len - 1\n",
    "            distorted_symbol = round(1 + (len(list_words[i]) - 2) * random.random())\n",
    "            #print(\"{} - {}\".format(distorted_symbol, list_words[i]))\n",
    "            #print(\"{}---{}-{}-{}\".format(distorted_symbol, list_words[i][0:(distorted_symbol)], list_words[i][distorted_symbol - 1], list_words[i][distorted_symbol + 1 * (len(list_words[i]) > distorted_symbol):distorted_symbol + 1 * (len(list_words[i]) > distorted_symbol)]))\n",
    "            list_words[i] = list_words[i][0:(distorted_symbol)] + list_words[i][distorted_symbol - 1] + list_words[i][distorted_symbol + 1:]\n",
    "        \n",
    "        if swap_type == \"wordtrimright\":\n",
    "            # WORD TRIM RIGHT\n",
    "            ## min symbol = 1, max distorted symbol = len - 1\n",
    "            trim_from = round(1 + (len(list_words[i]) - 1) * random.random())\n",
    "            list_words[i] = list_words[i][:trim_from]\n",
    "    \n",
    "    if swap_type == \"wordswapprev\":\n",
    "        # WORD SWAP\n",
    "        word_id = round((len(list_words) - 2) * random.random())\n",
    "        s1 = list_words[word_id]\n",
    "        list_words[word_id] = list_words[word_id + 1]\n",
    "        list_words[word_id + 1] = s1\n",
    "        \n",
    "    if swap_type == \"deletespaces\":\n",
    "        # DELETE WHITESPACES\n",
    "        ## -2 because there are len - 1 spaces in total\n",
    "        space_id = round((len(list_words) - 2) * random.random())\n",
    "        list_words[space_id] = list_words[space_id] + list_words[space_id + 1]\n",
    "        list_words.pop(space_id + 1)\n",
    "            \n",
    "    distortedText = \" \".join(list_words)\n",
    "    return distortedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Antons likes pizza\"\n",
    "print(distortText(text=text,swap_type=\"symbolswap\"))\n",
    "\n",
    "print(distortText(text=text,swap_type=\"symboldelete\"))\n",
    "\n",
    "print(distortText(text=text,swap_type=\"symbolreplacerandom\"))\n",
    "\n",
    "print(distortText(text=text,swap_type=\"symbolreplaceprev\"))\n",
    "\n",
    "print(distortText(text=text,swap_type=\"wordtrimright\"))\n",
    "\n",
    "print(distortText(text=text,swap_type=\"wordswapprev\"))\n",
    "\n",
    "print(distortText(text=text,swap_type=\"deletespaces\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = Wikipedia(\n",
    "    language=\"simple\",\n",
    "    cache_directory_url=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = {'a' : 0, 'b': 1, 'c':2, 'd':3, 'e':4, 'f':5, 'g':6, 'h':7, 'i':8, 'j':9, 'k':10, 'l':11, 'm':12, 'n':13, 'o':14,\n",
    "            'p':15, 'q':16, 'r':17, 's':18, 't':19, 'u':20, 'v':21, 'w':22, 'x':23, 'y':24, 'z':25, \n",
    "            '0':26, '1':27, '2':28, '3':29, '4':30, '5':31, '6':32, '7':33, '8':34, '9':35, \n",
    "            ' ':36, ',':37, '.':38, ':':39, ';':40, '\"':41, \"'\":42, '':43} #43 = unknown symbol\n",
    "\n",
    "idxs = [alphabets[ch] if ch in alphabets else 43 for ch in 'az 123#']\n",
    "\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = tf.one_hot(idxs, depth=len(alphabets), dtype=tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "one_hot.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up simple wikipedia texts\n",
    "pattern_ignored_words = re.compile(\n",
    "    r\"\"\"\n",
    "    (?:(?:thumb|thumbnail|left|right|\\d+px|upright(?:=[0-9\\.]+)?)\\|)+\n",
    "    |^\\s*\\|.+$\n",
    "    |^REDIRECT\\b\"\"\",\n",
    "    flags=re.DOTALL | re.UNICODE | re.VERBOSE | re.MULTILINE)\n",
    "pattern_new_lines = re.compile('[\\n\\r ]+', re.UNICODE)\n",
    "texts = [wikipedia.documents[i].text for i in range(len(wikipedia.documents))]\n",
    "texts = [pattern_ignored_words.sub('', texts[i]) for i in range(len(texts))]\n",
    "texts = [pattern_new_lines.sub(' ', texts[i]) for i in range(len(texts))]\n",
    "texts = [texts[i].replace(\"\\\\\", \"\") for i in range(len(texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple wikipedia article texts into single sentences\n",
    "sentences += [texts[i].split(\". \") for i in range(len(texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences[10000:10020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
